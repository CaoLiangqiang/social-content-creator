#!/usr/bin/env python3
"""
çœŸå®URLé›†æˆæµ‹è¯•

> ğŸ§ª åŸºäºç”¨æˆ·æä¾›çš„çœŸå®URLè¿›è¡Œå…¨é¢æµ‹è¯•
> å¼€å‘è€…: æ™ºå® (AIåŠ©æ‰‹)
"""

import asyncio
import sys
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


# ç”¨æˆ·æä¾›çš„çœŸå®URL
REAL_URLS = {
    'æŠ–éŸ³': 'https://v.douyin.com/arLquTQPBYM/',
    'Bç«™': 'https://b23.tv/gp9M5rR',
    'å°çº¢ä¹¦': 'http://xhslink.com/o/7McoywOZWas'
}


async def test_bilibili_real_url():
    """æµ‹è¯•Bç«™çœŸå®URL"""
    print("\n" + "="*70)
    print("ğŸ¬ Bç«™çˆ¬è™«æµ‹è¯•")
    print("="*70)

    try:
        from src.crawler.bilibili.bilibili_crawler import BilibiliCrawler
        import aiohttp
        import re

        url = REAL_URLS['Bç«™']
        print(f"URL: {url}")

        # è§£æçŸ­é“¾æ¥
        async with aiohttp.ClientSession() as session:
            async with session.head(url, allow_redirects=True) as response:
                real_url = str(response.url)
        print(f"çœŸå®URL: {real_url}")

        # æå–BVID
        bvid_match = re.search(r'BV[a-zA-Z0-9]{10}', real_url)
        if not bvid_match:
            print("âŒ æ— æ³•æå–BVID")
            return None

        bvid = bvid_match.group(0)
        print(f"BVID: {bvid}")

        # çˆ¬å–è§†é¢‘
        crawler = BilibiliCrawler()
        video_data = await crawler.crawl_video_full(bvid)

        if video_data and video_data.get('video_info'):
            video_info = video_data['video_info']

            result = {
                'platform': 'Bç«™',
                'url': url,
                'bvid': bvid,
                'title': video_info.get('title', 'N/A'),
                'desc': video_info.get('desc', 'N/A')[:100],
                'play_count': video_info.get('play_count', 0),
                'like_count': video_info.get('like_count', 0),
                'coin_count': video_info.get('coin_count', 0),
                'favorite_count': video_info.get('favorite_count', 0),
                'author': video_info.get('author', 'N/A'),
                'duration': video_info.get('length', 'N/A'),
                'cid': video_info.get('cid', 'N/A')
            }

            print(f"\nâœ… Bç«™çˆ¬å–æˆåŠŸï¼")
            print(f"æ ‡é¢˜: {result['title']}")
            print(f"æ’­æ”¾: {result['play_count']:,}")
            print(f"ç‚¹èµ: {result['like_count']:,}")
            print(f"æŠ•å¸: {result['coin_count']:,}")
            print(f"æ”¶è—: {result['favorite_count']:,}")
            print(f"UPä¸»: {result['author']}")

            return result
        else:
            print("âŒ Bç«™çˆ¬å–å¤±è´¥")
            return None

    except Exception as e:
        print(f"âŒ Bç«™æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_douyin_real_url():
    """æµ‹è¯•æŠ–éŸ³çœŸå®URL"""
    print("\n" + "="*70)
    print("ğŸµ æŠ–éŸ³çˆ¬è™«æµ‹è¯•")
    print("="*70)

    try:
        from src.crawler.douyin.douyin_crawler import DouyinCrawler

        url = REAL_URLS['æŠ–éŸ³']
        print(f"URL: {url}")

        crawler = DouyinCrawler()
        video = await crawler.crawl_video_by_url(url)

        if video:
            result = {
                'platform': 'æŠ–éŸ³',
                'url': url,
                'video_id': video.video_id,
                'title': video.title,
                'desc': video.desc[:100],
                'digg_count': video.statistics.digg_count,
                'comment_count': video.statistics.comment_count,
                'share_count': video.statistics.share_count,
                'collect_count': video.statistics.collect_count,
                'play_count': video.statistics.play_count,
                'author': video.author.nickname,
                'author_follower': video.author.follower_count,
                'duration': video.video.duration,
                'width': video.video.width,
                'height': video.video.height,
                'tags': [t.get('hashtag_name', '') for t in video.text_extra]
            }

            print(f"\nâœ… æŠ–éŸ³çˆ¬å–æˆåŠŸï¼")
            print(f"æ ‡é¢˜: {result['title'][:50]}")
            print(f"ç‚¹èµ: {result['digg_count']:,}")
            print(f"è¯„è®º: {result['comment_count']:,}")
            print(f"åˆ†äº«: {result['share_count']:,}")
            print(f"æ”¶è—: {result['collect_count']:,}")
            print(f"åˆ›ä½œè€…: {result['author']}")
            print(f"ç²‰ä¸: {result['author_follower']:,}")
            print(f"æ ‡ç­¾: {', '.join(result['tags'][:5])}")

            return result
        else:
            print("âŒ æŠ–éŸ³çˆ¬å–å¤±è´¥")
            return None

    except Exception as e:
        print(f"âŒ æŠ–éŸ³æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_xiaohongshu_real_url():
    """æµ‹è¯•å°çº¢ä¹¦çœŸå®URL"""
    print("\n" + "="*70)
    print("ğŸ“• å°çº¢ä¹¦çˆ¬è™«æµ‹è¯•")
    print("="*70)

    try:
        from src.crawler.xiaohongshu.xiaohongshu_crawler import XiaohongshuCrawler

        url = REAL_URLS['å°çº¢ä¹¦']
        print(f"URL: {url}")
        print("â¸ï¸ å°çº¢ä¹¦éœ€è¦content_idï¼Œæš‚æ—¶è·³è¿‡")

        result = {
            'platform': 'å°çº¢ä¹¦',
            'url': url,
            'status': 'skipped',
            'note': 'éœ€è¦content_idæ‰èƒ½çˆ¬å–'
        }

        return result

    except Exception as e:
        print(f"âŒ å°çº¢ä¹¦æµ‹è¯•å¤±è´¥: {e}")
        return None


async def save_results(results: dict):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""

    # ä¿å­˜ä¸ºJSON
    output_file = project_root / 'test_results' / f'test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    output_file.parent.mkdir(exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # ä¿å­˜ä¸ºMarkdownæŠ¥å‘Š
    report_file = project_root / 'test_results' / f'report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# çœŸå®URLé›†æˆæµ‹è¯•æŠ¥å‘Š\n\n")
        f.write(f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")

        for platform, data in results.items():
            if data and data.get('status') != 'skipped':
                f.write(f"## {platform}\n\n")
                f.write(f"**URL**: {data.get('url', 'N/A')}\n\n")

                # åŸºç¡€ä¿¡æ¯
                if data.get('title'):
                    f.write(f"**æ ‡é¢˜**: {data['title']}\n\n")

                # ç»Ÿè®¡æ•°æ®
                f.write("### ğŸ“Š ç»Ÿè®¡æ•°æ®\n\n")
                stats = []

                if data.get('play_count'):
                    stats.append(f"æ’­æ”¾: {data['play_count']:,}")
                if data.get('like_count') or data.get('digg_count'):
                    like_count = data.get('like_count') or data.get('digg_count')
                    stats.append(f"ç‚¹èµ: {like_count:,}")
                if data.get('coin_count'):
                    stats.append(f"æŠ•å¸: {data['coin_count']:,}")
                if data.get('favorite_count') or data.get('collect_count'):
                    fav_count = data.get('favorite_count') or data.get('collect_count')
                    stats.append(f"æ”¶è—: {fav_count:,}")
                if data.get('comment_count'):
                    stats.append(f"è¯„è®º: {data['comment_count']:,}")
                if data.get('share_count'):
                    stats.append(f"åˆ†äº«: {data['share_count']:,}")

                f.write(" | ".join(stats) + "\n\n")

                # ä½œè€…ä¿¡æ¯
                if data.get('author'):
                    f.write("### ğŸ‘¤ ä½œè€…ä¿¡æ¯\n\n")
                    f.write(f"**åç§°**: {data['author']}\n\n")
                    if data.get('author_follower'):
                        f.write(f"**ç²‰ä¸**: {data['author_follower']:,}\n\n")

                f.write("---\n\n")

    print(f"ğŸ“ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     çœŸå®URLé›†æˆæµ‹è¯• - æ™ºå®å‡ºå“ ğŸŒ¸                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æµ‹è¯•URLï¼ˆç”¨æˆ·æä¾›çš„çœŸå®é“¾æ¥ï¼‰ï¼š
""")

    for platform, url in REAL_URLS.items():
        print(f"{platform:8s}: {url}")

    print("\nå¼€å§‹æµ‹è¯•...\n")

    results = {}

    # æµ‹è¯•Bç«™
    results['Bç«™'] = await test_bilibili_real_url()

    # æµ‹è¯•æŠ–éŸ³
    results['æŠ–éŸ³'] = await test_douyin_real_url()

    # æµ‹è¯•å°çº¢ä¹¦
    results['å°çº¢ä¹¦'] = await test_xiaohongshu_real_url()

    # æ‰“å°ç»“æœæ±‡æ€»
    print("\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*70)

    for platform, data in results.items():
        if data:
            if data.get('status') == 'skipped':
                status = "â¸ï¸ è·³è¿‡"
            else:
                status = "âœ… æˆåŠŸ"
        else:
            status = "âŒ å¤±è´¥"
        print(f"{platform:8s} {status}")

    success_count = sum(1 for r in results.values() if r and r.get('status') != 'skipped')
    total_count = len([r for r in results.values() if r and r.get('status') != 'skipped'])

    print("="*70)
    print(f"æˆåŠŸç‡: {success_count}/{total_count} ({success_count*100//total_count if total_count > 0 else 0}%)")
    print("="*70)

    # ä¿å­˜ç»“æœ
    await save_results(results)

    if success_count == total_count and total_count > 0:
        print("\nğŸ‰ æ‰€æœ‰å¹³å°æµ‹è¯•é€šè¿‡ï¼çˆ¬è™«ç³»ç»Ÿå®Œå…¨æ­£å¸¸ï¼")
        print("\nğŸ“‹ æµ‹è¯•æ•°æ®å·²ä¿å­˜ï¼Œå¯ç”¨äºï¼š")
        print("  - æ•°æ®åˆ†æ")
        print("  - å†…å®¹æ¨è")
        print("  - è¶‹åŠ¿åˆ†æ")
        print("  - ç«å“ç›‘æ§")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†å¹³å°æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        return 1


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
