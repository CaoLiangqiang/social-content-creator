#!/usr/bin/env python3
"""
å¤šå¹³å°åšä¸»æ¯æ—¥ç›‘æ§ç³»ç»Ÿ

> æ”¯æŒBç«™ã€æŠ–éŸ³ã€å°çº¢ä¹¦ç­‰å¹³å°
> AIè‡ªåŠ¨æ€»ç»“æ–°å†…å®¹
> å¼€å‘è€…: æ™ºå® (AIåŠ©æ‰‹)
"""

import asyncio
import aiohttp
import json
from datetime import datetime, timedelta
from pathlib import Path
import sys
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥Bç«™çˆ¬è™«
from src.crawler.bilibili.bilibili_crawler import BilibiliCrawler


class MultiPlatformMonitor:
    """å¤šå¹³å°ç›‘æ§ç³»ç»Ÿ"""

    def __init__(self):
        self.data_dir = Path('/home/admin/openclaw/workspace/projects/social-content-creator/data')
        self.data_dir.mkdir(exist_ok=True)

        # åšä¸»æ•°æ®åº“
        self.bloggers_file = self.data_dir / 'multi_platform_bloggers.json'
        # å†…å®¹è®°å½•æ•°æ®åº“
        self.content_file = self.data_dir / 'multi_platform_content.json'
        # æ¯æ—¥æŠ¥å‘Šç›®å½•
        self.reports_dir = self.data_dir / 'multi_platform_reports'
        self.reports_dir.mkdir(exist_ok=True)

        # CookieåŠ è½½
        self.bilibili_cookie = self._load_cookie('bilibili_cookies.json')

    def _load_cookie(self, filename):
        """åŠ è½½cookie"""
        cookie_file = project_root / filename
        if cookie_file.exists():
            with open(cookie_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('cookie_string', '')
        return ''

    def load_bloggers(self):
        """åŠ è½½åšä¸»åˆ—è¡¨"""
        if self.bloggers_file.exists():
            with open(self.bloggers_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # é»˜è®¤åšä¸»åˆ—è¡¨ï¼ˆä»ä¹‹å‰çš„æµ‹è¯•æ•°æ®ï¼‰
            return {
                'bloggers': [
                    # Bç«™ - ä½¿ç”¨ä½ ä¹‹å‰å…³æ³¨çš„åšä¸»
                    {'platform': 'bilibili', 'name': 'è€ç•ªèŒ„', 'mid': '546195', 'enabled': True},

                    # å¯ä»¥æ·»åŠ æ›´å¤šåšä¸»
                    # {'platform': 'bilibili', 'name': 'ç‹èµ›åš', 'mid': '197823715', 'enabled': True},
                ],
                'last_check': None
            }

    def save_bloggers(self, data):
        """ä¿å­˜åšä¸»åˆ—è¡¨"""
        with open(self.bloggers_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def load_content(self):
        """åŠ è½½å†…å®¹è®°å½•"""
        if self.content_file.exists():
            with open(self.content_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {'content': {}, 'last_updated': None}

    def save_content(self, data):
        """ä¿å­˜å†…å®¹è®°å½•"""
        with open(self.content_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    async def get_bilibili_videos(self, mid: str, num: int = 20):
        """è·å–Bç«™ç”¨æˆ·æœ€æ–°è§†é¢‘ï¼ˆä½¿ç”¨BilibiliCrawlerï¼‰"""
        try:
            crawler = BilibiliCrawler(cookie_string=self.bilibili_cookie)

            # è·å–è§†é¢‘åˆ—è¡¨
            result = await crawler.get_user_videos(mid, page=1, page_size=num)

            if result and result['videos']:
                videos = []
                for video in result['videos']:
                    videos.append({
                        'id': video.get('bvid', ''),
                        'title': video.get('title', ''),
                        'description': video.get('description', ''),
                        'play': video.get('play', 0),
                        'comment': video.get('comment', 0),
                        'length': video.get('duration', ''),
                        'created': video.get('created', 0),
                        'type': 'video'
                    })
                return videos, None
            else:
                return [], 'æœªè·å–åˆ°è§†é¢‘'

        except Exception as e:
            return None, str(e)

    async def get_douyin_videos(self, user_id: str, num: int = 20):
        """è·å–æŠ–éŸ³ç”¨æˆ·æœ€æ–°è§†é¢‘ï¼ˆå¾…å®ç°ï¼‰"""
        return [], 'æŠ–éŸ³çˆ¬è™«å¾…å®ç°'

    async def get_xiaohongshu_content(self, user_id: str, num: int = 20):
        """è·å–å°çº¢ä¹¦ç”¨æˆ·æœ€æ–°å†…å®¹"""
        # ä»ç”¨æˆ·ä¸Šä¼ çš„JSONæ–‡ä»¶è¯»å–
        xiaohongshu_data_file = self.data_dir / 'xiaohongshu_user_data.json'

        if xiaohongshu_data_file.exists():
            with open(xiaohongshu_data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # è½¬æ¢ä¸ºç›‘æ§ç³»ç»Ÿæ ¼å¼
            notes = data.get('notes', [])
            content_list = []

            for note in notes[:num]:
                content_list.append({
                    'id': note.get('note_id', ''),
                    'title': note.get('title', ''),
                    'description': note.get('desc', ''),
                    'liked_count': note.get('liked_count', 0),
                    'collected_count': note.get('collected_count', 0),
                    'comment_count': note.get('comment_count', 0),
                    'created': note.get('time', ''),
                    'type': 'note'
                })

            return content_list, None
        else:
            return [], 'æœªæ‰¾åˆ°å°çº¢ä¹¦æ•°æ®æ–‡ä»¶ï¼ˆè¯·å…ˆè¿è¡Œxiaohongshu_local_crawler.pyå¹¶ä¸Šä¼ æ•°æ®ï¼‰'

    async def get_platform_content(self, platform: str, user_id: str):
        """æ ¹æ®å¹³å°è·å–å†…å®¹"""
        if platform == 'bilibili':
            return await self.get_bilibili_videos(user_id, num=20)
        elif platform == 'douyin':
            return await self.get_douyin_videos(user_id, num=20)
        elif platform == 'xiaohongshu':
            return await self.get_xiaohongshu_content(user_id, num=20)
        else:
            return None, f'æœªçŸ¥å¹³å°: {platform}'

    def is_new_content(self, content_data, platform: str, content_id: str):
        """æ£€æŸ¥æ˜¯å¦æ˜¯æ–°å†…å®¹"""
        key = f"{platform}:{content_id}"

        if key not in content_data['content']:
            return True

        return False

    async def ai_summarize(self, content: dict):
        """ä½¿ç”¨AIæ€»ç»“å†…å®¹"""
        title = content.get('title', '')
        description = content.get('description', '')
        play = content.get('play', 0)
        liked_count = content.get('liked_count', 0)

        # åˆ¤æ–­çƒ­åº¦
        if platform := content.get('platform'):
            if platform == 'bilibili':
                hotness = 'çƒ­é—¨' if play > 10000 else 'æ™®é€š'
            elif platform == 'xiaohongshu':
                hotness = 'çƒ­é—¨' if liked_count > 1000 else 'æ™®é€š'
            else:
                hotness = 'æ™®é€š'
        else:
            hotness = 'æ™®é€š'

        # ç®€å•æ‘˜è¦é€»è¾‘
        summary = {
            'hotness': hotness,
            'topics': [],
            'summary': (description[:150] + '...') if len(description) > 150 else description or 'æš‚æ— ç®€ä»‹'
        }

        # æå–å¯èƒ½çš„è¯é¢˜æ ‡ç­¾
        combined_text = f"{title} {description}"

        if 'AI' in combined_text:
            summary['topics'].append('AI')
        if 'æ•™ç¨‹' in combined_text or 'guide' in combined_text.lower():
            summary['topics'].append('æ•™ç¨‹')
        if 'çˆ¬è™«' in combined_text or 'crawler' in combined_text.lower():
            summary['topics'].append('çˆ¬è™«')
        if 'è‡ªåŠ¨åŒ–' in combined_text or 'automation' in combined_text.lower():
            summary['topics'].append('è‡ªåŠ¨åŒ–')

        return summary

    async def check_blogger(self, blogger: dict, content_data: dict):
        """æ£€æŸ¥å•ä¸ªåšä¸»"""
        platform = blogger['platform']
        name = blogger['name']
        user_id = blogger.get('mid') or blogger.get('user_id', '')

        print(f"\n{'='*70}")
        print(f"æ£€æŸ¥: [{platform.upper()}] {name} (id: {user_id})")
        print('='*70)

        # è·å–å†…å®¹
        content_list, error = await self.get_platform_content(platform, user_id)

        if content_list is None:
            print(f"  âŒ å¤±è´¥: {error}")
            return [], error

        if not content_list:
            print(f"  âš ï¸ æš‚æ— å†…å®¹: {error}")
            return [], error

        print(f"  âœ… è·å–åˆ° {len(content_list)} æ¡å†…å®¹")

        # æ£€æŸ¥æ–°å†…å®¹
        new_content = []

        for content in content_list:
            content_id = content['id']

            if self.is_new_content(content_data, platform, content_id):
                # AIæ€»ç»“
                summary = await self.ai_summarize(content)

                new_content.append({
                    'platform': platform,
                    'blogger': name,
                    'content': content,
                    'summary': summary,
                    'discovered_at': datetime.now().isoformat()
                })

                # æ›´æ–°è®°å½•
                key = f"{platform}:{content_id}"
                content_data['content'][key] = {
                    'id': content_id,
                    'title': content['title'],
                    'platform': platform,
                    'blogger': name,
                    'first_seen': datetime.now().isoformat()
                }

                print(f"  âœ¨ æ–°å†…å®¹: {content['title'][:50]}")

        if new_content:
            print(f"\n  ğŸ‰ å‘ç° {len(new_content)} ä¸ªæ–°å†…å®¹ï¼")
        else:
            print(f"\n  â„¹ï¸ æš‚æ— æ–°å†…å®¹")

        return new_content, None

    async def daily_check(self):
        """æ¯æ—¥æ£€æŸ¥"""
        print("="*70)
        print("å¤šå¹³å°åšä¸»æ¯æ—¥ç›‘æ§ç³»ç»Ÿ - æ™ºå®å‡ºå“")
        print("="*70)

        # åŠ è½½æ•°æ®
        bloggers_data = self.load_bloggers()
        content_data = self.load_content()

        bloggers = [b for b in bloggers_data['bloggers'] if b.get('enabled', True)]

        print(f"\næ£€æŸ¥åšä¸»æ•°é‡: {len(bloggers)}")

        # å¦‚æœæœ‰Bç«™åšä¸»ï¼Œç­‰å¾…é¢‘ç‡é™åˆ¶å†·å´
        bilibili_bloggers = [b for b in bloggers if b['platform'] == 'bilibili']
        if bilibili_bloggers:
            print("\nâ³ ç­‰å¾…30ç§’è®©Bç«™APIé¢‘ç‡é™åˆ¶å†·å´...")
            await asyncio.sleep(30)

        # æŒ‰å¹³å°åˆ†ç»„
        by_platform = {}
        for blogger in bloggers:
            platform = blogger['platform']
            if platform not in by_platform:
                by_platform[platform] = []
            by_platform[platform].append(blogger)

        print(f"å¹³å°åˆ†å¸ƒ: {', '.join([f'{p}:{len(by_platform[p])}' for p in by_platform])}")

        all_new_content = []
        errors = []

        # æ£€æŸ¥æ¯ä¸ªåšä¸»
        for i, blogger in enumerate(bloggers, 1):
            print(f"\nè¿›åº¦: [{i}/{len(bloggers)}]")

            new_content, error = await self.check_blogger(blogger, content_data)

            if new_content:
                all_new_content.extend(new_content)

            if error:
                errors.append({
                    'blogger': blogger['name'],
                    'platform': blogger['platform'],
                    'error': error
                })

            # Bç«™éœ€è¦ç­‰å¾…é¿å…é¢‘ç‡é™åˆ¶
            if blogger['platform'] == 'bilibili' and i < len(bloggers):
                print(f"\nâ³ ç­‰å¾…90ç§’åç»§ç»­...")
                await asyncio.sleep(90)  # å¢åŠ åˆ°90ç§’

        # ä¿å­˜å†…å®¹è®°å½•
        content_data['last_updated'] = datetime.now().isoformat()
        self.save_content(content_data)

        # æ›´æ–°æœ€åæ£€æŸ¥æ—¶é—´
        bloggers_data['last_check'] = datetime.now().isoformat()
        self.save_bloggers(bloggers_data)

        # ç”Ÿæˆæ—¥æŠ¥
        if all_new_content or errors:
            await self.generate_daily_report(all_new_content, errors)
        else:
            print("\n" + "="*70)
            print("ä»Šæ—¥æ— æ–°å†…å®¹")
            print("="*70)

        return all_new_content, errors

    async def generate_daily_report(self, new_content, errors):
        """ç”Ÿæˆæ—¥æŠ¥"""
        today = datetime.now().strftime('%Y-%m-%d')
        report_file = self.reports_dir / f'{today}.md'

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# å¤šå¹³å°åšä¸»æ—¥æŠ¥\n\n")
            f.write(f"**æ—¥æœŸ**: {today}\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}\n\n")
            f.write("---\n\n")

            # æŒ‰å¹³å°åˆ†ç»„
            by_platform = {}
            for item in new_content:
                platform = item['platform']
                if platform not in by_platform:
                    by_platform[platform] = []
                by_platform[platform].append(item)

            # ç»Ÿè®¡
            f.write("## ğŸ“Š ä»Šæ—¥ç»Ÿè®¡\n\n")
            f.write(f"- **æ–°å†…å®¹æ•°é‡**: {len(new_content)}\n")
            f.write(f"- **æ¶‰åŠå¹³å°**: {len(by_platform)}\n")

            for platform, items in by_platform.items():
                f.write(f"- **{platform.upper()}**: {len(items)} æ¡\n")

            f.write("\n")

            # æŒ‰å¹³å°å±•ç¤º
            platform_names = {
                'bilibili': 'ğŸ“º Bç«™',
                'douyin': 'ğŸµ æŠ–éŸ³',
                'xiaohongshu': 'ğŸ“• å°çº¢ä¹¦'
            }

            for platform in ['bilibili', 'douyin', 'xiaohongshu']:
                if platform not in by_platform:
                    continue

                items = by_platform[platform]

                f.write(f"## {platform_names.get(platform, platform.upper())}\n\n")

                for item in items:
                    summary = item['summary']
                    content = item['content']

                    f.write(f"### {content['title']}\n\n")
                    f.write(f"**åšä¸»**: {item['blogger']}\n")
                    f.write(f"**çƒ­åº¦**: {summary['hotness']} | ")

                    if content.get('play'):
                        f.write(f"**æ’­æ”¾**: {content['play']:,} | ")
                        f.write(f"**è¯„è®º**: {content.get('comment', 0):,}\n\n")
                    elif content.get('liked_count'):
                        f.write(f"**ç‚¹èµ**: {content['liked_count']:,} | ")
                        f.write(f"**æ”¶è—**: {content.get('collected_count', 0):,}\n\n")
                    else:
                        f.write("\n")

                    # AIæ‘˜è¦
                    f.write(f"**AIæ‘˜è¦**: {summary['summary']}\n")

                    if summary['topics']:
                        f.write(f"**è¯é¢˜æ ‡ç­¾**: {', '.join(summary['topics'])}\n")

                    f.write(f"\n---\n\n")

            # é”™è¯¯æŠ¥å‘Š
            if errors:
                f.write("## âš ï¸ æ£€æŸ¥é”™è¯¯\n\n")

                for error in errors:
                    f.write(f"- [{error['platform'].upper()}] **{error['blogger']}**: {error['error']}\n")

                f.write("\n")

        print(f"\nâœ… æ—¥æŠ¥å·²ç”Ÿæˆ: {report_file}")

        # ç”Ÿæˆç®€çŸ­æ‘˜è¦
        summary_file = self.reports_dir / f'{today}_summary.txt'

        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"å¤šå¹³å°åšä¸»æ—¥æŠ¥ - {today}\n")
            f.write("="*70 + "\n\n")

            if new_content:
                f.write(f"ğŸ‰ ä»Šæ—¥å‘ç° {len(new_content)} æ¡æ–°å†…å®¹\n\n")

                for item in new_content:
                    platform = item['platform'].upper()
                    blogger = item['blogger']
                    title = item['content']['title']

                    f.write(f"[{platform}] {blogger}: {title}\n")
            else:
                f.write("ä»Šæ—¥æš‚æ— æ–°å†…å®¹\n")

            if errors:
                f.write(f"\nâš ï¸ {len(errors)} ä¸ªåšä¸»æ£€æŸ¥å¤±è´¥\n")

        print(f"âœ… æ‘˜è¦å·²ç”Ÿæˆ: {summary_file}")


async def main():
    """ä¸»å‡½æ•°"""
    monitor = MultiPlatformMonitor()

    # æ‰§è¡Œæ¯æ—¥æ£€æŸ¥
    new_content, errors = await monitor.daily_check()

    print("\n" + "="*70)
    print("æ£€æŸ¥å®Œæˆï¼")
    print("="*70)

    print(f"\næ–°å†…å®¹: {len(new_content)}")
    print(f"é”™è¯¯: {len(errors)}")

    if new_content:
        print("\nâœ¨ å‘ç°æ–°å†…å®¹ï¼Œæ—¥æŠ¥å·²ç”Ÿæˆï¼")
        print(f"ğŸ“ æŸ¥çœ‹æ—¥æŠ¥: {monitor.reports_dir / datetime.now().strftime('%Y-%m-%d') + '.md'}")


if __name__ == "__main__":
    asyncio.run(main())
