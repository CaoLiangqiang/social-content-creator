# å¼€å‘ç»éªŒæ€»ç»“ä¸é”™è¯¯é¿å…æŒ‡å—

## ğŸ¯ ç›®çš„
è®°å½•å¼€å‘è¿‡ç¨‹ä¸­çš„é—®é¢˜åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼Œé¿å…åœ¨å¼€å‘è¿‡ç¨‹ä¸­çŠ¯åŒæ ·çš„é”™è¯¯ã€‚

---

## ğŸ”§ ç¯å¢ƒé…ç½®é—®é¢˜

### é—®é¢˜1: Node.jsç‰ˆæœ¬ä¸å…¼å®¹
**é”™è¯¯è¡¨ç°**:
```
Error: The module was compiled against a different Node.js version
```

**åŸå› åˆ†æ**:
- é¡¹ç›®ä½¿ç”¨Node.js v20ç‰¹æ€§ï¼Œä½†ç³»ç»Ÿå®‰è£…çš„æ˜¯v18
- package.jsonä¸­engineså­—æ®µæœªä¸¥æ ¼é™åˆ¶ç‰ˆæœ¬

**è§£å†³æ–¹æ¡ˆ**:
```json
{
  "engines": {
    "node": ">=20.0.0 <21.0.0",
    "npm": ">=9.0.0"
  }
}
```

**é¢„é˜²æªæ–½**:
- åœ¨é¡¹ç›®READMEä¸­æ˜ç¡®Node.jsç‰ˆæœ¬è¦æ±‚
- ä½¿ç”¨.nvmrcæ–‡ä»¶é”å®šNode.jsç‰ˆæœ¬
- åœ¨CI/CDä¸­å¢åŠ ç‰ˆæœ¬æ£€æŸ¥

### é—®é¢˜2: Pythonä¾èµ–å†²çª
**é”™è¯¯è¡¨ç°**:
```
ImportError: cannot import name 'urlparse' from 'urllib.parse'
```

**åŸå› åˆ†æ**:
- é¡¹ç›®ä½¿ç”¨çš„Pythonç‰ˆæœ¬æ˜¯3.11ï¼Œä½†æŸäº›åº“è¦æ±‚3.9
- è™šæ‹Ÿç¯å¢ƒæœªæ­£ç¡®é…ç½®

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨pyenvç®¡ç†Pythonç‰ˆæœ¬
pyenv install 3.11.0
pyenv local 3.11.0

# ä¸¥æ ¼çš„ä¾èµ–ç‰ˆæœ¬ç®¡ç†
pip freeze > requirements.txt
```

**é¢„é˜²æªæ–½**:
- åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.python-versionæ–‡ä»¶
- ä½¿ç”¨requirements.txtä¸¥æ ¼ç®¡ç†ä¾èµ–ç‰ˆæœ¬
- åœ¨CIä¸­å¢åŠ Pythonç‰ˆæœ¬æ£€æŸ¥

---

## ğŸ—„ï¸ æ•°æ®åº“é—®é¢˜

### é—®é¢˜3: PostgreSQLè¿æ¥æ± è€—å°½
**é”™è¯¯è¡¨ç°**:
```
Error: remaining connection slots are reserved for non-replication superuser connections
```

**åŸå› åˆ†æ**:
- åº”ç”¨æœªæ­£ç¡®é‡Šæ”¾æ•°æ®åº“è¿æ¥
- è¿æ¥æ± é…ç½®è¿‡å¤§ï¼Œè¶…è¿‡äº†PostgreSQLæœ€å¤§è¿æ¥æ•°

**è§£å†³æ–¹æ¡ˆ**:
```javascript
// æ­£ç¡®çš„è¿æ¥æ± é…ç½®
const pool = new Pool({
  host: 'localhost',
  database: 'social_content',
  max: 20, // æ ¹æ®å®é™…å¹¶å‘è°ƒæ•´
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
})

// ç¡®ä¿è¿æ¥é‡Šæ”¾
async function query(sql, params) {
  const client = await pool.connect()
  try {
    const result = await client.query(sql, params)
    return result
  } finally {
    client.release() // å…³é”®ï¼šé‡Šæ”¾è¿æ¥
  }
}
```

**é¢„é˜²æªæ–½**:
- ç›‘æ§æ•°æ®åº“è¿æ¥æ•°
- è®¾ç½®åˆç†çš„è¿æ¥æ± å¤§å°
- ä½¿ç”¨è¿æ¥æ± ç›‘æ§å·¥å…·
- å®šæœŸæ£€æŸ¥ä»£ç ä¸­çš„è¿æ¥æ³„æ¼

### é—®é¢˜4: Redisç¼“å­˜ç©¿é€
**é”™è¯¯è¡¨ç°**:
- å¤§é‡è¯·æ±‚ç›´æ¥æ‰“åˆ°æ•°æ®åº“
- Rediså‘½ä¸­ç‡æä½

**åŸå› åˆ†æ**:
- æ¶æ„è¯·æ±‚ä¸å­˜åœ¨çš„æ•°æ®
- ç¼“å­˜è¿‡æœŸæ—¶é—´è®¾ç½®ä¸å½“

**è§£å†³æ–¹æ¡ˆ**:
```javascript
// å¸ƒéš†è¿‡æ»¤å™¨é˜²æ­¢ç¼“å­˜ç©¿é€
const { BloomFilter } = require('bloom-filters')

const filter = new BloomFilter(10000, 0.01) // å®¹é‡10000ï¼Œè¯¯åˆ¤ç‡1%

async function getContent(id) {
  // å…ˆæ£€æŸ¥å¸ƒéš†è¿‡æ»¤å™¨
  if (!filter.has(id)) {
    return null // ä¸å­˜åœ¨çš„ID
  }
  
  // æ£€æŸ¥ç¼“å­˜
  let content = await redis.get(`content:${id}`)
  if (content) {
    return JSON.parse(content)
  }
  
  // æŸ¥è¯¢æ•°æ®åº“
  content = await db.query('SELECT * FROM contents WHERE id = $1', [id])
  if (content) {
    filter.add(id) // åŠ å…¥å¸ƒéš†è¿‡æ»¤å™¨
    await redis.setex(`content:${id}`, 3600, JSON.stringify(content))
  }
  
  return content
}
```

**é¢„é˜²æªæ–½**:
- ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨
- è®¾ç½®åˆç†çš„ç¼“å­˜è¿‡æœŸæ—¶é—´
- ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡

---

## ğŸ•·ï¸ çˆ¬è™«é—®é¢˜

### é—®é¢˜5: åçˆ¬è™«æœºåˆ¶è§¦å‘
**é”™è¯¯è¡¨ç°**:
```
HTTP 403 Forbidden
IPè¢«å°ç¦
éªŒè¯ç é¢‘ç¹å‡ºç°
```

**åŸå› åˆ†æ**:
- è¯·æ±‚é¢‘ç‡è¿‡é«˜
- User-Agentè¢«è¯†åˆ«
- IPåœ°å€è¢«æ ‡è®°

**è§£å†³æ–¹æ¡ˆ**:
```python
import asyncio
import random
from fake_useragent import UserAgent

class SmartCrawler:
    def __init__(self):
        self.session = aiohttp.ClientSession()
        self.ua = UserAgent()
        
    async def crawl_with_backoff(self, url, max_retries=3):
        for attempt in range(max_retries):
            try:
                headers = {
                    'User-Agent': self.ua.random,
                    'Referer': 'https://www.xiaohongshu.com/'
                }
                
                # æ™ºèƒ½å»¶è¿Ÿ
                await asyncio.sleep(random.uniform(1, 3))
                
                async with self.session.get(url, headers=headers) as response:
                    if response.status == 200:
                        return await response.text()
                    elif response.status == 403:
                        # è§¦å‘åçˆ¬ï¼Œå¢åŠ å»¶è¿Ÿé‡è¯•
                        await asyncio.sleep(60)
                        continue
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(2 ** attempt) # æŒ‡æ•°é€€é¿
                
    async def use_proxy(self):
        # ä½¿ç”¨ä»£ç†æ± 
        proxy = await self.proxy_pool.get()
        return proxy
```

**é¢„é˜²æªæ–½**:
- ä½¿ç”¨çœŸå®çš„æµè§ˆå™¨User-Agent
- å®ç°æ™ºèƒ½çš„è¯·æ±‚å»¶è¿Ÿ
- å»ºç«‹ä»£ç†æ± 
- ç›‘æ§çˆ¬è™«å¥åº·åº¦

### é—®é¢˜6: åŠ¨æ€å†…å®¹åŠ è½½å¤±è´¥
**é”™è¯¯è¡¨ç°**:
- çˆ¬å–çš„HTMLä¸å®Œæ•´
- JSæ¸²æŸ“çš„å†…å®¹ç¼ºå¤±

**åŸå› åˆ†æ**:
- ç½‘ç«™ä½¿ç”¨React/Vueç­‰å‰ç«¯æ¡†æ¶
- å†…å®¹é€šè¿‡AJAXåŠ¨æ€åŠ è½½

**è§£å†³æ–¹æ¡ˆ**:
```python
from playwright.async_api import async_playwright

class DynamicCrawler:
    async def crawl_dynamic_content(self, url):
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            
            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            await page.goto(url, wait_until='networkidle')
            
            # ç­‰å¾…ç‰¹å®šå…ƒç´ åŠ è½½
            await page.wait_for_selector('.content-container')
            
            # æå–æ¸²æŸ“åçš„HTML
            content = await page.content()
            
            await browser.close()
            return content
```

**é¢„é˜²æªæ–½**:
- è¯†åˆ«åŠ¨æ€å†…å®¹ç½‘ç«™
- ä½¿ç”¨Playwrightæˆ–Selenium
- åˆç†è®¾ç½®ç­‰å¾…ç­–ç•¥

---

## ğŸ¤– AIæœåŠ¡é—®é¢˜

### é—®é¢˜7: OpenAI APIé™æµ
**é”™è¯¯è¡¨ç°**:
```
Error: Rate limit exceeded
```

**åŸå› åˆ†æ**:
- çŸ­æ—¶é—´å†…è¯·æ±‚è¿‡å¤š
- æœªå®ç°è¯·æ±‚é˜Ÿåˆ—ç®¡ç†

**è§£å†³æ–¹æ¡ˆ**:
```python
import time
from queue import Queue
from threading import Thread

class OpenAIQueue:
    def __init__(self, requests_per_minute=20):
        self.queue = Queue()
        self.rpm = requests_per_minute
        self.last_request_time = None
        
    async def call_api(self, func, *args, **kwargs):
        # è®¡ç®—æœ€å°è¯·æ±‚é—´éš”
        min_interval = 60.0 / self.rpm
        
        if self.last_request_time:
            elapsed = time.time() - self.last_request_time
            if elapsed < min_interval:
                await asyncio.sleep(min_interval - elapsed)
        
        result = await func(*args, **kwargs)
        self.last_request_time = time.time()
        return result
```

**é¢„é˜²æªæ–½**:
- å®ç°è¯·æ±‚é˜Ÿåˆ—
- è®¾ç½®åˆç†çš„é™æµå‚æ•°
- ç›‘æ§APIä½¿ç”¨é‡
- å‡†å¤‡å¤‡ç”¨APIå¯†é’¥

### é—®é¢˜8: å†…å®¹ç”Ÿæˆè´¨é‡ä¸ç¨³å®š
**é”™è¯¯è¡¨ç°**:
- ç”Ÿæˆçš„å†…å®¹è´¨é‡å·®å¼‚å¤§
- å¶å°”å‡ºç°ä¸ç›¸å…³å†…å®¹

**åŸå› åˆ†æ**:
- æ¸©åº¦å‚æ•°è®¾ç½®ä¸å½“
- Promptä¸å¤Ÿæ¸…æ™°
- æ¨¡å‹ç‰ˆæœ¬é€‰æ‹©é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
```python
class ContentGenerator:
    def __init__(self):
        self.prompts = {
            'xiaohongshu': self._get_xiaohongshu_prompt(),
            'weibo': self._get_weibo_prompt(),
            'zhihu': self._get_zhihu_prompt()
        }
        
    def _get_xiaohongshu_prompt(self):
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°çº¢ä¹¦å†…å®¹åˆ›ä½œåŠ©æ‰‹ã€‚

## ä»»åŠ¡è¦æ±‚
1. æ ¹æ®æä¾›çš„åŸå§‹å†…å®¹ï¼Œç”Ÿæˆç¬¦åˆå°çº¢ä¹¦è°ƒæ€§çš„çˆ†æ¬¾ç¬”è®°
2. æ ‡é¢˜è¦å¸å¼•çœ¼çƒï¼Œä½¿ç”¨æ•°å­—ã€æ‚¬å¿µç­‰æŠ€å·§
3. å†…å®¹è¦æœ‰çœŸå®æ„Ÿå’Œä»£å…¥æ„Ÿ
4. åˆç†ä½¿ç”¨emojiï¼Œä½†ä¸èƒ½è¿‡åº¦
5. è¯é¢˜æ ‡ç­¾è¦ç²¾å‡†ä¸”çƒ­é—¨

## è¾“å‡ºæ ¼å¼
æ ‡é¢˜ï¼š[ç”Ÿæˆçš„æ ‡é¢˜]
å†…å®¹ï¼š[ç”Ÿæˆçš„æ­£æ–‡å†…å®¹]
æ ‡ç­¾ï¼š[æ¨èçš„5-8ä¸ªè¯é¢˜æ ‡ç­¾]

## åŸå§‹å†…å®¹
{content}
"""

    async def generate(self, platform, content, quality_check=True):
        prompt = self.prompts[platform].format(content=content)
        
        # ä½¿ç”¨ä¸åŒçš„æ¸©åº¦å‚æ•°å°è¯•ç”Ÿæˆ
        candidates = []
        for temp in [0.6, 0.7, 0.8]:
            result = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=temp
            )
            candidates.append(result)
        
        if quality_check:
            # è´¨é‡æ£€æŸ¥
            scored_candidates = [
                (self._quality_score(c), c) for c in candidates
            ]
            return max(scored_candidates)[1]
        
        return candidates[0]
```

**é¢„é˜²æªæ–½**:
- è®¾è®¡æ¸…æ™°çš„Promptæ¨¡æ¿
- ä½¿ç”¨æ¸©åº¦å‚æ•°ç”Ÿæˆå¤šä¸ªå€™é€‰
- å®ç°å†…å®¹è´¨é‡è¯„åˆ†æœºåˆ¶
- æ”¶é›†ç”¨æˆ·åé¦ˆä¼˜åŒ–Prompt

---

## ğŸš€ æ€§èƒ½é—®é¢˜

### é—®é¢˜9: å†…å­˜æ³„æ¼
**é”™è¯¯è¡¨ç°**:
- Node.jsè¿›ç¨‹å†…å­˜æŒç»­å¢é•¿
- æœ€ç»ˆè§¦å‘OOMé”™è¯¯

**åŸå› åˆ†æ**:
- äº‹ä»¶ç›‘å¬å™¨æœªæ­£ç¡®ç§»é™¤
- ç¼“å­˜æ— é™åˆ¶å¢é•¿
- å®šæ—¶å™¨æœªæ¸…ç†

**è§£å†³æ–¹æ¡ˆ**:
```javascript
// å†…å­˜æ³„æ¼æ£€æµ‹å·¥å…·
const leaky = require('leak')

// å®šæœŸæ‰§è¡Œå†…å­˜æ£€æŸ¥
setInterval(() => {
  const usage = process.memoryUsage()
  console.log('Memory usage:', usage)
  
  // å †å¿«ç…§
  if (usage.heapUsed > 500 * 1024 * 1024) { // 500MB
    leaky.dump('/tmp/heap-snapshot.heapsnapshot')
  }
}, 60000)

// æ­£ç¡®çš„äº‹ä»¶ç›‘å¬å™¨ç®¡ç†
class EventManager {
  constructor() {
    this.listeners = []
  }
  
  on(event, handler) {
    this.listeners.push({ event, handler })
    return this
  }
  
  removeAll() {
    this.listeners.forEach(({ event, handler }) => {
      emitter.removeListener(event, handler)
    })
    this.listeners = []
  }
}
```

**é¢„é˜²æªæ–½**:
- ä½¿ç”¨Chrome DevToolsè¿›è¡Œå†…å­˜åˆ†æ
- å®šæœŸè¿›è¡Œå†…å­˜æ³„æ¼æ£€æµ‹
- å®ç°ç¼“å­˜æ·˜æ±°ç­–ç•¥
- æ­£ç¡®ç®¡ç†äº‹ä»¶ç›‘å¬å™¨

### é—®é¢˜10: CPUå ç”¨è¿‡é«˜
**é”™è¯¯è¡¨ç°**:
- çˆ¬è™«è¿›ç¨‹CPUå ç”¨100%
- ç³»ç»Ÿå“åº”å˜æ…¢

**åŸå› åˆ†æ**:
- æœªä½¿ç”¨å¹¶å‘æ§åˆ¶
- åŒæ­¥æ“ä½œé˜»å¡äº‹ä»¶å¾ªç¯
- æ­£åˆ™è¡¨è¾¾å¼æ€§èƒ½é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class ConcurrencyController:
    def __init__(self, max_concurrent=10):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.executor = ThreadPoolExecutor(max_workers=max_concurrent)
    
    async def run_with_limit(self, coro):
        async with self.semaphore:
            return await coro
    
    async def crawl_parallel(self, urls):
        tasks = [
            self.run_with_limit(self.crawl_single(url))
            for url in urls
        ]
        return await asyncio.gather(*tasks)
```

**é¢„é˜²æªæ–½**:
- ä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·
- å®ç°å¹¶å‘æ§åˆ¶
- ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦
- ä½¿ç”¨å¼‚æ­¥IOæ“ä½œ

---

## ğŸ” å®‰å…¨é—®é¢˜

### é—®é¢˜11: SQLæ³¨å…¥æ¼æ´
**é”™è¯¯è¡¨ç°**:
- å®‰å…¨æ‰«ææŠ¥å‘ŠSQLæ³¨å…¥æ¼æ´
- æ•°æ®å¯èƒ½è¢«æ¶æ„ç¯¡æ”¹

**åŸå› åˆ†æ**:
- ç›´æ¥æ‹¼æ¥SQLè¯­å¥
- æœªä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢

**è§£å†³æ–¹æ¡ˆ**:
```javascript
// âŒ é”™è¯¯åšæ³•
async function getUserUnsafe(username) {
  const sql = `SELECT * FROM users WHERE username = '${username}'`
  return await db.query(sql)
}

// âœ… æ­£ç¡®åšæ³•
async function getUserSafe(username) {
  const sql = 'SELECT * FROM users WHERE username = $1'
  return await db.query(sql, [username])
}
```

**é¢„é˜²æªæ–½**:
- ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
- å¯ç”¨SQLæ³¨å…¥æ£€æµ‹å·¥å…·
- å®šæœŸè¿›è¡Œå®‰å…¨å®¡è®¡
- ä½¿ç”¨ORM/Query Builder

### é—®é¢˜12: æ•æ„Ÿä¿¡æ¯æ³„éœ²
**é”™è¯¯è¡¨ç°**:
- æ—¥å¿—ä¸­åŒ…å«ç”¨æˆ·å¯†ç 
- APIå“åº”è¿”å›æ•æ„Ÿå­—æ®µ

**åŸå› åˆ†æ**:
- æ—¥å¿—è®°å½•ä¸å½“
- APIåºåˆ—åŒ–ä¸å®Œæ•´

**è§£å†³æ–¹æ¡ˆ**:
```javascript
// æ•æ„Ÿå­—æ®µè¿‡æ»¤
const SENSITIVE_FIELDS = ['password', 'token', 'secret', 'key']

function sanitize(obj) {
  if (typeof obj !== 'object') return obj
  
  const sanitized = {}
  for (const [key, value] of Object.entries(obj)) {
    if (SENSITIVE_FIELDS.some(field => key.toLowerCase().includes(field))) {
      sanitized[key] = '***REDACTED***'
    } else {
      sanitized[key] = sanitize(value)
    }
  }
  return sanitized
}

// å®‰å…¨çš„æ—¥å¿—è®°å½•
console.log('User data:', sanitize(userData))
```

**é¢„é˜²æªæ–½**:
- å®ç°æ•°æ®è„±æ•ä¸­é—´ä»¶
- å®¡æŸ¥æ‰€æœ‰æ—¥å¿—è¾“å‡º
- ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿé…ç½®
- å®šæœŸè¿›è¡Œå®‰å…¨æ‰«æ

---

## ğŸ“‹ ä»£ç è´¨é‡é—®é¢˜

### é—®é¢˜13: ç¼ºä¹é”™è¯¯å¤„ç†
**é”™è¯¯è¡¨ç°**:
- åº”ç”¨å› æœªæ•è·å¼‚å¸¸è€Œå´©æºƒ
- é”™è¯¯ä¿¡æ¯ä¸å‹å¥½

**è§£å†³æ–¹æ¡ˆ**:
```javascript
// å…¨å±€é”™è¯¯å¤„ç†
process.on('uncaughtException', (error) => {
  logger.error('Uncaught Exception:', error)
  // ä¼˜é›…å…³é—­
  gracefulShutdown()
})

process.on('unhandledRejection', (reason, promise) => {
  logger.error('Unhandled Rejection at:', promise, 'reason:', reason)
})

// APIé”™è¯¯å¤„ç†ä¸­é—´ä»¶
app.use((err, req, res, next) => {
  logger.error('API Error:', err)
  
  if (err.type === 'entity.parse.failed') {
    return res.status(400).json({
      error: 'Invalid JSON',
      message: err.message
    })
  }
  
  res.status(500).json({
    error: 'Internal Server Error',
    message: process.env.NODE_ENV === 'production' 
      ? 'Something went wrong' 
      : err.message
  })
})
```

### é—®é¢˜14: ç¼ºä¹æ—¥å¿—è®°å½•
**è§£å†³æ–¹æ¡ˆ**:
```javascript
// ç»“æ„åŒ–æ—¥å¿—
const winston = require('winston')

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' })
  ]
})

// è®°å½•å…³é”®æ“ä½œ
logger.info('Content generated', {
  userId: user.id,
  contentId: content.id,
  platform: 'xiaohongshu'
})
```

---

## ğŸ”§ è°ƒè¯•æŠ€å·§

### æ€§èƒ½åˆ†æ
```bash
# Node.jsæ€§èƒ½åˆ†æ
node --prof app.js
node --prof-process isolate-*.log > profile.txt

# Pythonæ€§èƒ½åˆ†æ
python -m cProfile -o profile.stats app.py
python -m pstats profile.stats
```

### å†…å­˜åˆ†æ
```bash
# Node.jså †å¿«ç…§
node --heap-prof app.js

# Pythonå†…å­˜åˆ†æ
python -m memory_profiler app.py
```

### å¹¶å‘è°ƒè¯•
```bash
# é”ç«äº‰æ£€æµ‹
python -m trace --trace app.py

# æ­»é”æ£€æµ‹
gdb -p <pid>
```

---

## ğŸ“š æœ€ä½³å®è·µæ€»ç»“

### ä»£ç è§„èŒƒ
1. **ç»Ÿä¸€ä»£ç é£æ ¼**: ä½¿ç”¨ESLint/Prettier
2. **ç±»å‹å®‰å…¨**: TypeScript + Python Type Hints
3. **æ–‡æ¡£å®Œæ•´**: å‡½æ•°æ³¨é‡Šã€APIæ–‡æ¡£
4. **æµ‹è¯•è¦†ç›–**: å•å…ƒæµ‹è¯• > 80%

### Gitå·¥ä½œæµ
1. **åˆ†æ”¯ç®¡ç†**: feature/*åˆ†æ”¯å¼€å‘
2. **æäº¤è§„èŒƒ**: Conventional Commits
3. **ä»£ç å®¡æŸ¥**: å¼ºåˆ¶Code Review
4. **ç‰ˆæœ¬æ ‡ç­¾**: è¯­ä¹‰åŒ–ç‰ˆæœ¬

### éƒ¨ç½²æµç¨‹
1. **ç¯å¢ƒéš”ç¦»**: dev/test/staging/prod
2. **è‡ªåŠ¨åŒ–éƒ¨ç½²**: CI/CD Pipeline
3. **å›æ»šå‡†å¤‡**: ä¿ç•™å†å²ç‰ˆæœ¬
4. **ç›‘æ§å‘Šè­¦**: å®æ—¶ç›‘æ§ç³»ç»Ÿ

---

*æ–‡æ¡£ç‰ˆæœ¬: v1.0*  
*åˆ›å»ºæ—¥æœŸ: 2026-02-12*  
*æœ€åæ›´æ–°: 2026-02-12*  
*ç»´æŠ¤è€…: æ™ºå® (AIåŠ©æ‰‹)*