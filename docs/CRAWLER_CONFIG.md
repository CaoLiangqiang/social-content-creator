# çˆ¬è™«é…ç½®è¯´æ˜

> ğŸ•·ï¸ ç¤¾äº¤å†…å®¹åˆ›ä½œå¹³å° - çˆ¬è™«æ¨¡å—é…ç½®æŒ‡å—  
> åˆ›å»ºæ—¥æœŸ: 2026-02-12  
> ç»´æŠ¤è€…: æ™ºå® (AIåŠ©æ‰‹)

---

## ğŸ“‹ é…ç½®æ¸…å•

### 1. å¿…éœ€é…ç½®

#### Cookieé…ç½®ï¼ˆå°çº¢ä¹¦å¿…éœ€ï¼‰

å°çº¢ä¹¦çš„å¤§éƒ¨åˆ†APIéœ€è¦ç™»å½•æ€ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è·å–Cookieï¼š

**æ­¥éª¤ï¼š**
1. æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® `https://www.xiaohongshu.com`
2. ç™»å½•è´¦å·
3. æ‰“å¼€å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰â†’ Application/åº”ç”¨ â†’ Cookies
4. å¤åˆ¶æ‰€æœ‰Cookieï¼ˆç‰¹åˆ«æ˜¯ `web_session` å’Œ `a1` ï¼‰
5. é…ç½®åˆ°ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶

**é…ç½®æ–¹å¼ï¼š**
```bash
# .env æ–‡ä»¶
XIAOHONGSHU_COOKIE="web_session=xxxxx; a1=xxxxx; ..."
```

**æˆ–åœ¨ä»£ç ä¸­è®¾ç½®ï¼š**
```python
crawler = XiaohongshuCrawler()
crawler.set_cookie("web_session=xxxxx; a1=xxxxx; ...")
```

**âš ï¸ é‡è¦æç¤ºï¼š**
- Cookieæœ‰æœ‰æ•ˆæœŸï¼Œéœ€è¦å®šæœŸæ›´æ–°
- å»ºè®®ä½¿ç”¨å°å·ï¼Œé¿å…ä¸»å·è¢«å°
- ä¸è¦åˆ†äº«Cookieç»™ä»–äºº

---

### 2. ä»£ç†IPé…ç½®ï¼ˆå¯é€‰ä½†æ¨èï¼‰

ç”±äºå°çº¢ä¹¦æœ‰è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼Œä½¿ç”¨ä»£ç†IPå¯ä»¥æé«˜çˆ¬å–æ•ˆç‡ã€‚

**å…è´¹ä»£ç†ï¼ˆä¸æ¨èï¼ŒæˆåŠŸç‡ä½ï¼‰ï¼š**
```python
from src.crawler.base import ProxyPool

pool = ProxyPool()
pool.add_proxy('127.0.0.1', 7890, protocol='http')  # æœ¬åœ°ä»£ç†
```

**ä»˜è´¹ä»£ç†ï¼ˆæ¨èï¼‰ï¼š**
- å¿«ä»£ç†ï¼šhttps://www.kuaidaili.com/
- é˜¿å¸ƒäº‘ï¼šhttps://www.abuyun.com/
- èŠéº»ä»£ç†ï¼šhttps://www.zhimaruanjian.com/

**é…ç½®ç¤ºä¾‹ï¼š**
```python
# ä»ä»£ç†æœåŠ¡è·å–API
proxy_api_url = "https://your-proxy-api/get"

# æ·»åŠ åˆ°ä»£ç†æ± 
pool.add_proxy(
    host='proxy.example.com',
    port=8080,
    username='your_username',
    password='your_password',
    protocol='http'
)
```

---

### 3. APIç«¯ç‚¹é…ç½®ï¼ˆé‡è¦ï¼‰

âš ï¸ **å½“å‰çŠ¶æ€ï¼šä»£ç ä¸­çš„APIç«¯ç‚¹æ˜¯ç¤ºä¾‹ï¼Œéœ€è¦éªŒè¯ï¼**

**éœ€è¦é€šè¿‡æŠ“åŒ…ç¡®è®¤çœŸå®ç«¯ç‚¹ï¼š**

1. **ä½¿ç”¨Charles/FiddleræŠ“åŒ…**
   - å®‰è£…Charles/Fiddler
   - é…ç½®HTTPSè¯ä¹¦
   - æ‰‹æœºè®¾ç½®ä»£ç†
   - æ‰“å¼€å°çº¢ä¹¦App
   - æŸ¥çœ‹APIè¯·æ±‚

2. **å…³é”®ç«¯ç‚¹éœ€è¦ç¡®è®¤ï¼š**
   - æœç´¢ç¬”è®°ï¼š`/sns/web/v1/search/notes`
   - ç¬”è®°è¯¦æƒ…ï¼š`/sns/web/v1/feed`
   - ç”¨æˆ·ä¿¡æ¯ï¼š`/sns/web/v1/user/{id}/info`
   - è¯„è®ºåˆ—è¡¨ï¼š`/sns/web/v2/comment/page`

3. **å“åº”ç»“æ„éªŒè¯ï¼š**
   - å­—æ®µåç§°ï¼ˆå¦‚ `note_card`, `interact_info`ï¼‰
   - æ—¶é—´æˆ³æ ¼å¼ï¼ˆæ¯«ç§’/ç§’ï¼‰
   - åˆ†é¡µå‚æ•°

**å¦‚æœæ‚¨å·²ç»æŒæ¡äº†çœŸå®ç«¯ç‚¹ï¼Œè¯·æ›´æ–°ä»¥ä¸‹æ–‡ä»¶ï¼š**
- `src/crawler/xiaohongshu/xiaohongshu_crawler.py`

---

### 4. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# å°çº¢ä¹¦é…ç½®
XIAOHONGSHU_COOKIE="your_cookie_here"
XIAOHONGSHU_RATE_LIMIT=5

# ä»£ç†é…ç½®
HTTP_PROXY=""
HTTPS_PROXY=""
PROXY_USERNAME=""
PROXY_PASSWORD=""

# æ•°æ®åº“é…ç½®
DB_HOST=localhost
DB_PORT=5432
DB_NAME=social_content_creator
DB_USER=postgres
DB_PASSWORD=your_password

# Redisé…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=logs/crawler.log
```

---

### 5. ä¾èµ–å®‰è£…

```bash
# å®‰è£…Pythonä¾èµ–
cd src/crawler
pip install -r requirements.txt

# å®‰è£…Playwrightæµè§ˆå™¨
playwright install chromium
```

**å¦‚æœå®‰è£…å¤±è´¥ï¼Œå°è¯•ï¼š**
```bash
# ä½¿ç”¨å›½å†…é•œåƒ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

---

## ğŸ§ª æµ‹è¯•é…ç½®

### 1. éªŒè¯Cookieæ˜¯å¦æœ‰æ•ˆ

```python
import asyncio
from src.crawler.xiaohongshu import XiaohongshuCrawler

async def test_cookie():
    crawler = XiaohongshuCrawler()
    crawler.set_cookie("your_cookie_here")
    
    # å°è¯•çˆ¬å–ç”¨æˆ·ä¿¡æ¯
    user_info = await crawler.crawl_user_info("test_user_id")
    
    if user_info:
        print("Cookieæœ‰æ•ˆï¼")
        print(user_info)
    else:
        print("Cookieæ— æ•ˆæˆ–å·²è¿‡æœŸ")

asyncio.run(test_cookie())
```

### 2. éªŒè¯ä»£ç†æ˜¯å¦å¯ç”¨

```python
from src.crawler.base import ProxyPool
import asyncio

async def test_proxy():
    pool = ProxyPool()
    pool.add_proxy('your_proxy_host', port, username='xxx', password='xxx')
    
    proxy = pool.get_proxy()
    await pool.check_proxy_health(proxy)
    
    if proxy.is_available():
        print("ä»£ç†å¯ç”¨ï¼")
    else:
        print("ä»£ç†ä¸å¯ç”¨")

asyncio.run(test_proxy())
```

### 3. è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
cd src/crawler
python tests/test_xiaohongshu.py
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### é—®é¢˜1: 403 Forbidden
**åŸå› **: Cookieæ— æ•ˆæˆ–IPè¢«å°
**è§£å†³**: 
- æ›´æ–°Cookie
- ä½¿ç”¨ä»£ç†IP
- é™ä½è¯·æ±‚é¢‘ç‡

### é—®é¢˜2: è¿”å›ç©ºæ•°æ®
**åŸå› **: APIç«¯ç‚¹é”™è¯¯æˆ–å‚æ•°é—®é¢˜
**è§£å†³**:
- é€šè¿‡æŠ“åŒ…ç¡®è®¤çœŸå®ç«¯ç‚¹
- æ£€æŸ¥è¯·æ±‚å‚æ•°æ ¼å¼

### é—®é¢˜3: é¢‘ç¹è§¦å‘éªŒè¯ç 
**åŸå› **: è¯·æ±‚è¿‡äºé¢‘ç¹
**è§£å†³**:
- å¢åŠ è¯·æ±‚å»¶è¿Ÿ
- ä½¿ç”¨å¤šä¸ªè´¦å·Cookieè½®æ¢
- ä½¿ç”¨ä»£ç†IP

### é—®é¢˜4: Cookieå¿«é€Ÿå¤±æ•ˆ
**åŸå› **: è´¦å·å¼‚å¸¸æˆ–è¢«å°
**è§£å†³**:
- ä½¿ç”¨æ–°è´¦å·
- é¿å…é¢‘ç¹è¯·æ±‚
- æ¨¡æ‹Ÿæ­£å¸¸ç”¨æˆ·è¡Œä¸º

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å¹¶å‘æ§åˆ¶
```python
# ä¸è¦è¶…è¿‡10ä¸ªå¹¶å‘
MAX_CONCURRENT_REQUESTS = 10
```

### 2. è¯·æ±‚å»¶è¿Ÿ
```python
# æ¯æ¬¡è¯·æ±‚é—´éš”2-5ç§’
import random
await asyncio.sleep(random.uniform(2, 5))
```

### 3. ç¼“å­˜ç­–ç•¥
- å¯¹å·²çˆ¬å–çš„å†…å®¹è¿›è¡Œç¼“å­˜
- é¿å…é‡å¤çˆ¬å–

---

## ğŸ”’ å®‰å…¨å»ºè®®

1. **Cookieå®‰å…¨**
   - ä¸è¦æäº¤åˆ°Gitä»“åº“
   - å®šæœŸæ›´æ–°
   - ä½¿ç”¨å°å·

2. **ä»£ç†å®‰å…¨**
   - ä½¿ç”¨å¯ä¿¡èµ–çš„ä»£ç†æœåŠ¡
   - ä¸è¦åœ¨ä»£ç†ä¸­ä¼ è¾“æ•æ„Ÿæ•°æ®

3. **æ³•å¾‹åˆè§„**
   - ä»…ç”¨äºå­¦ä¹ ç ”ç©¶
   - éµå®ˆrobots.txt
   - ä¸ä¾µçŠ¯éšç§
   - æ§åˆ¶çˆ¬å–é¢‘ç‡

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœæ‚¨åœ¨é…ç½®è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ï¼š

1. â“ **ä¸ç¡®å®šAPIç«¯ç‚¹æ˜¯å¦æ­£ç¡®** - éœ€è¦é€šè¿‡æŠ“åŒ…ç¡®è®¤
2. â“ **Cookieé…ç½®ä¸å·¥ä½œ** - å¯èƒ½éœ€è¦æ–°çš„Cookie
3. â“ **ä»£ç†IPé…ç½®å›°éš¾** - æ¨èä½¿ç”¨ä»˜è´¹ä»£ç†æœåŠ¡

**è¯·é€šè¿‡é£ä¹¦è”ç³»æˆ‘ï¼** ğŸ“±

---

*é…ç½®æŒ‡å—ç‰ˆæœ¬: v1.0*  
*æœ€åæ›´æ–°: 2026-02-12*  
*ç»´æŠ¤è€…: æ™ºå® (AIåŠ©æ‰‹)*
