#!/usr/bin/env python3
"""
æŠ–éŸ³é¡µé¢åˆ†æå·¥å…·

> ğŸ” åˆ†ææŠ–éŸ³é¡µé¢ç»“æ„
> å¼€å‘è€…: æ™ºå® (AIåŠ©æ‰‹)
"""

import requests
import re
import json
from bs4 import BeautifulSoup


def analyze_douyin_page(url):
    """åˆ†ææŠ–éŸ³é¡µé¢"""
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1'
    }
    
    print("è®¿é—®é¡µé¢...")
    response = requests.get(url, headers=headers, allow_redirects=True)
    
    print(f"çŠ¶æ€ç : {response.status_code}")
    print(f"æœ€ç»ˆURL: {response.url}")
    print(f"å†…å®¹é•¿åº¦: {len(response.text)}")
    
    # ä¿å­˜å®Œæ•´HTML
    with open('/tmp/douyin_full.html', 'w', encoding='utf-8') as f:
        f.write(response.text)
    print("å®Œæ•´HTMLå·²ä¿å­˜åˆ° /tmp/douyin_full.html")
    
    # è§£æ
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # æŸ¥æ‰¾æ‰€æœ‰script
    scripts = soup.find_all('script')
    print(f"\\næ‰¾åˆ° {len(scripts)} ä¸ªscriptæ ‡ç­¾")
    
    # åˆ†ææ¯ä¸ªscript
    for i, script in enumerate(scripts):
        script_text = script.string or ''
        
        if not script_text:
            continue
        
        print(f"\\nScript #{i}:")
        print(f"  é•¿åº¦: {len(script_text)}")
        
        # æŸ¥æ‰¾å…³é”®è¯
        keywords = ['__INITIAL_STATE__', 'videoData', 'aweme', 'videoInfo', 'window.__']
        found_keywords = [kw for kw in keywords if kw in script_text]
        
        if found_keywords:
            print(f"  å…³é”®è¯: {found_keywords}")
            
            # ä¿å­˜æœ‰ä»·å€¼çš„script
            if any(kw in script_text for kw in ['__INITIAL_STATE__', 'videoData', 'aweme']):
                filename = f'/tmp/douyin_script_{i}.js'
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(script_text)
                print(f"  å·²ä¿å­˜åˆ° {filename}")
                
                # å°è¯•è§£æJSON
                try:
                    # å°è¯•ä¸åŒçš„æ¨¡å¼
                    patterns = [
                        r'window\\.__INITIAL_STATE__\\s*=\\s*(\\{.*?\\});',
                        r'__INITIAL_STATE__\\s*=\\s*(\\{.*?\\});',
                        r'(\\{[^{}]*"[^"]*"aweme"[^"]*":[^}]*\\})',
                    ]
                    
                    for pattern in patterns:
                        matches = re.findall(pattern, script_text, re.DOTALL)
                        if matches:
                            print(f"  æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…ï¼ˆæ¨¡å¼: {pattern[:30]}...ï¼‰")
                            
                            for j, match in enumerate(matches[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                                try:
                                    data = json.loads(match)
                                    print(f"  JSON #{j}: {list(data.keys())[:10]}")
                                except:
                                    pass
                except Exception as e:
                    pass
    
    # æŸ¥æ‰¾metaæ ‡ç­¾
    print("\\n\\nåˆ†æmetaæ ‡ç­¾:")
    meta_tags = soup.find_all('meta')
    
    interesting_meta = ['og:title', 'og:description', 'og:video', 'og:image']
    
    for meta in meta_tags:
        prop = meta.get('property') or meta.get('name')
        if prop and any(interest in prop for interest in interesting_meta):
            content = meta.get('content', '')
            print(f"  {prop}: {content[:100]}")


if __name__ == "__main__":
    url = "https://v.douyin.com/arLquTQPBYM/"
    print("="*60)
    print("æŠ–éŸ³é¡µé¢åˆ†æ")
    print("="*60)
    print(f"URL: {url}\\n")
    
    analyze_douyin_page(url)
    
    print("\\n" + "="*60)
    print("åˆ†æå®Œæˆï¼")
    print("="*60)
    print("\\næ–‡ä»¶å·²ä¿å­˜åˆ° /tmp/")
    print("å¯ä»¥æ‰‹åŠ¨åˆ†æè¿™äº›æ–‡ä»¶ä»¥äº†è§£æ•°æ®ç»“æ„")
