"""
AIå†…å®¹ç”ŸæˆæœåŠ¡
åŸºäºFastAPIæ¡†æ¶ï¼Œæä¾›å†…å®¹ç”Ÿæˆã€æ”¹å†™ã€åˆ†æç­‰åŠŸèƒ½
"""

import os
import re
from typing import Dict, List, Optional
from datetime import datetime

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import openai
from tenacity import retry, stop_after_attempt, wait_exponential

# é…ç½®
app = FastAPI(
    title="SCCP AI Service",
    description="AIå†…å®¹ç”ŸæˆæœåŠ¡",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAIé…ç½®
openai.api_key = os.getenv("OPENAI_API_KEY", "")
DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
FALLBACK_MODE = not openai.api_key or openai.api_key == "your-openai-api-key"


# æ•°æ®æ¨¡å‹
class XiaohongshuGenerateRequest(BaseModel):
    """å°çº¢ä¹¦å†…å®¹ç”Ÿæˆè¯·æ±‚"""
    topic: str = Field(..., min_length=1, max_length=200, description="å†…å®¹ä¸»é¢˜")
    style: str = Field(default="å¹²è´§åˆ†äº«", description="å†…å®¹é£æ ¼")
    keywords: List[str] = Field(default=[], max_length=10, description="å…³é”®è¯")
    tone: str = Field(default="è½»æ¾", description="è¯­æ°”")
    length: str = Field(default="medium", description="é•¿åº¦")


class TitleOptimizeRequest(BaseModel):
    """æ ‡é¢˜ä¼˜åŒ–è¯·æ±‚"""
    title: str = Field(..., min_length=1, max_length=100, description="åŸæ ‡é¢˜")
    platform: str = Field(default="xiaohongshu", description="ç›®æ ‡å¹³å°")
    count: int = Field(default=3, ge=1, le=10, description="ç”Ÿæˆæ•°é‡")


class ContentImproveRequest(BaseModel):
    """å†…å®¹æ”¹è¿›è¯·æ±‚"""
    content: str = Field(..., min_length=10, max_length=5000, description="åŸå§‹å†…å®¹")
    improvement_type: str = Field(default="general", description="æ”¹è¿›ç±»å‹")


class AnalysisRequest(BaseModel):
    """å†…å®¹åˆ†æè¯·æ±‚"""
    content: str = Field(..., min_length=10, max_length=5000, description="å†…å®¹")


class GenerateResponse(BaseModel):
    """ç”Ÿæˆå“åº”"""
    success: bool
    data: Dict
    message: str = "success"


# Promptæ¨¡æ¿
XIAOHONGSHU_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°çº¢ä¹¦å†…å®¹åˆ›ä½œè€…ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯åˆ›ä½œä¸€ç¯‡å°çº¢ä¹¦ç¬”è®°ï¼š

ä¸»é¢˜ï¼š{topic}
é£æ ¼ï¼š{style}
è¯­æ°”ï¼š{tone}
é•¿åº¦ï¼š{length}
å…³é”®è¯ï¼š{keywords}

è¦æ±‚ï¼š
1. æ ‡é¢˜è¦å¸å¼•äººï¼Œä½¿ç”¨emojiï¼Œæ§åˆ¶åœ¨20å­—ä»¥å†…
2. æ­£æ–‡è¦æœ‰å¹²è´§ï¼Œç»“æ„æ¸…æ™°ï¼Œä½¿ç”¨emojiç‚¹ç¼€
3. å¼€å¤´è¦æœ‰å¸å¼•åŠ›ï¼Œèƒ½ç•™ä½è¯»è€…
4. ä¸­é—´è¦æœ‰å®ç”¨å†…å®¹ï¼Œæä¾›ä»·å€¼
5. ç»“å°¾è¦æœ‰äº’åŠ¨ï¼Œå¼•å¯¼è¯„è®ºç‚¹èµ
6. æ·»åŠ ç›¸å…³è¯é¢˜æ ‡ç­¾ï¼Œ5-10ä¸ª
7. ä½¿ç”¨å°çº¢ä¹¦é£æ ¼ï¼Œäº²åˆ‡è‡ªç„¶

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
æ ‡é¢˜ï¼š[æ ‡é¢˜å†…å®¹]
æ­£æ–‡ï¼š[æ­£æ–‡å†…å®¹]
æ ‡ç­¾ï¼š[æ ‡ç­¾åˆ—è¡¨]
"""

TITLE_OPTIMIZE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ ‡é¢˜ä¼˜åŒ–ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ ‡é¢˜ä¼˜åŒ–{count}ä¸ªç‰ˆæœ¬ï¼š

åŸæ ‡é¢˜ï¼š{title}
ç›®æ ‡å¹³å°ï¼š{platform}

è¦æ±‚ï¼š
1. å¸å¼•äººç‚¹å‡»
2. ç¬¦åˆå¹³å°è°ƒæ€§
3. ä½¿ç”¨emojiå¢åŠ å¸å¼•åŠ›
4. æ§åˆ¶åœ¨20å­—ä»¥å†…
5. æ¯ä¸ªç‰ˆæœ¬è¦æœ‰ä¸åŒè§’åº¦

è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„æ ‡é¢˜åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªã€‚
"""

CONTENT_IMPROVE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹ç¼–è¾‘ã€‚è¯·æ”¹è¿›ä»¥ä¸‹å†…å®¹ï¼š

åŸå§‹å†…å®¹ï¼š
{content}

æ”¹è¿›ç±»å‹ï¼š{improvement_type}

è¦æ±‚ï¼š
1. ä¿æŒåŸæ„
2. ä¼˜åŒ–è¡¨è¾¾æ–¹å¼
3. å¢åŠ å¯è¯»æ€§
4. ä¿®æ­£è¯­æ³•é”™è¯¯
5. ä½¿å†…å®¹æ›´æµç•…

è¯·è¾“å‡ºæ”¹è¿›åçš„å†…å®¹ã€‚
"""


# å·¥å…·å‡½æ•°
def parse_xiaohongshu_content(text: str) -> Dict:
    """è§£æå°çº¢ä¹¦ç”Ÿæˆå†…å®¹"""
    result = {
        "title": "",
        "content": "",
        "tags": []
    }
    
    # è§£ææ ‡é¢˜
    title_match = re.search(r'æ ‡é¢˜[:ï¼š]\s*(.+?)(?=\n|$)', text)
    if title_match:
        result["title"] = title_match.group(1).strip()
    
    # è§£ææ­£æ–‡
    content_match = re.search(r'æ­£æ–‡[:ï¼š]\s*([\s\S]+?)(?=æ ‡ç­¾[:ï¼š]|$)', text)
    if content_match:
        result["content"] = content_match.group(1).strip()
    
    # è§£ææ ‡ç­¾
    tags_match = re.search(r'æ ‡ç­¾[:ï¼š]\s*(.+?)(?=\n|$)', text)
    if tags_match:
        tags_text = tags_match.group(1)
        # æå–æ ‡ç­¾ï¼ˆæ”¯æŒ #æ ‡ç­¾ æˆ– æ ‡ç­¾ æ ¼å¼ï¼‰
        tags = re.findall(r'#?([^#\s,]+)', tags_text)
        result["tags"] = [tag.strip() for tag in tags if tag.strip()]
    
    return result


def get_length_instruction(length: str) -> str:
    """è·å–é•¿åº¦è¯´æ˜"""
    lengths = {
        "short": "ç®€çŸ­ç²¾ç‚¼ï¼Œ100-200å­—",
        "medium": "ä¸­ç­‰é•¿åº¦ï¼Œ300-500å­—",
        "long": "è¯¦ç»†å…¨é¢ï¼Œ800-1000å­—"
    }
    return lengths.get(length, lengths["medium"])


# OpenAIè°ƒç”¨
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    reraise=True
)
async def call_openai(prompt: str, model: str = None) -> str:
    """è°ƒç”¨OpenAI API"""
    if FALLBACK_MODE:
        raise Exception("OpenAI API not configured")
    
    model = model or DEFAULT_MODEL
    
    response = await openai.ChatCompletion.acreate(
        model=model,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=2000
    )
    
    return response.choices[0].message.content


# Fallbackç”Ÿæˆå™¨
class FallbackGenerator:
    """å½“OpenAIä¸å¯ç”¨æ—¶ä½¿ç”¨çš„Fallbackç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_xiaohongshu(topic: str, style: str, keywords: List[str]) -> Dict:
        """ç”Ÿæˆå°çº¢ä¹¦å†…å®¹ï¼ˆFallbackï¼‰"""
        keyword_str = " ".join([f"#{k}" for k in keywords[:5]]) if keywords else "#å¹²è´§åˆ†äº«"
        
        title_templates = [
            f"âœ¨{topic}è¶…å…¨æ”»ç•¥ï¼å»ºè®®æ”¶è—",
            f"ğŸ”¥{topic}å¿…çœ‹ï¼æ–°æ‰‹ä¹Ÿèƒ½å­¦ä¼š",
            f"ğŸ’¡{topic}çš„ç§˜å¯†ï¼Œ90%çš„äººéƒ½ä¸çŸ¥é“",
            f"ğŸ“Œ{topic}å¹²è´§ï½œäº²æµ‹æœ‰æ•ˆ",
            f"ğŸŒŸ{topic}è¿™æ ·åšï¼Œæ•ˆæœç¿»å€"
        ]
        
        title = title_templates[hash(topic) % len(title_templates)]
        
        content = f"""å§å¦¹ä»¬ï¼ä»Šå¤©æ¥åˆ†äº«{topic}çš„è¶…å®ç”¨ç»éªŒğŸ’•

ã€ä¸ºä»€ä¹ˆé‡è¦ã€‘
{topic}çœŸçš„å¤ªé‡è¦äº†ï¼åšå¥½{topic}å¯ä»¥è®©æˆ‘ä»¬çš„ç”Ÿæ´»/å·¥ä½œæ›´åŠ é«˜æ•ˆâœ¨

ã€æ ¸å¿ƒè¦ç‚¹ã€‘
1ï¸âƒ£ é¦–å…ˆè¦æ˜ç¡®ç›®æ ‡ï¼ŒçŸ¥é“è‡ªå·±æƒ³è¦ä»€ä¹ˆ
2ï¸âƒ£ åˆ¶å®šè¯¦ç»†çš„è®¡åˆ’ï¼Œåˆ†æ­¥éª¤æ‰§è¡Œ
3ï¸âƒ£ åšæŒæ‰§è¡Œï¼Œä¸è¦è½»æ˜“æ”¾å¼ƒ
4ï¸âƒ£ åŠæ—¶å¤ç›˜æ€»ç»“ï¼Œä¸æ–­ä¼˜åŒ–æ”¹è¿›

ã€å®ç”¨æŠ€å·§ã€‘
ğŸ’¡ æŠ€å·§ä¸€ï¼šä»å°äº‹åšèµ·ï¼Œå¾ªåºæ¸è¿›
ğŸ’¡ æŠ€å·§äºŒï¼šæ‰¾åˆ°é€‚åˆè‡ªå·±çš„æ–¹æ³•
ğŸ’¡ æŠ€å·§ä¸‰ï¼šå¤šå‘ä¼˜ç§€çš„äººå­¦ä¹ 

ã€æ³¨æ„äº‹é¡¹ã€‘
âš ï¸ ä¸è¦ç›²ç›®è·Ÿé£ï¼Œè¦æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µ
âš ï¸ ä¿æŒè€å¿ƒï¼Œä¸è¦æ€¥äºæ±‚æˆ
âš ï¸ å®šæœŸå›é¡¾ï¼ŒåŠæ—¶è°ƒæ•´æ–¹å‘

å¸Œæœ›è¿™äº›åˆ†äº«å¯¹å¤§å®¶æœ‰å¸®åŠ©ï¼å¦‚æœè§‰å¾—æœ‰ç”¨è®°å¾—ç‚¹èµæ”¶è—å“¦ï½
æœ‰é—®é¢˜æ¬¢è¿åœ¨è¯„è®ºåŒºç•™è¨€äº¤æµğŸ’¬

{keyword_str} #å¹²è´§åˆ†äº« #ç»éªŒåˆ†äº« #ç”Ÿæ´»æŠ€å·§"""
        
        tags = keywords + ["å¹²è´§åˆ†äº«", "ç»éªŒåˆ†äº«", "ç”Ÿæ´»æŠ€å·§", "å®ç”¨æ”»ç•¥"]
        
        return {
            "title": title,
            "content": content,
            "tags": tags[:10]
        }
    
    @staticmethod
    def optimize_title(title: str, count: int = 3) -> List[str]:
        """ä¼˜åŒ–æ ‡é¢˜ï¼ˆFallbackï¼‰"""
        return [
            f"âœ¨{title}ï½œè¶…å…¨æ”»ç•¥",
            f"ğŸ”¥{title}å¿…çœ‹ï¼å»ºè®®æ”¶è—",
            f"ğŸ’¡{title}çš„ç§˜å¯†"
        ][:count]
    
    @staticmethod
    def improve_content(content: str) -> str:
        """æ”¹è¿›å†…å®¹ï¼ˆFallbackï¼‰"""
        return f"ã€ä¼˜åŒ–ç‰ˆã€‘\n\n{content}\n\nğŸ’¡ å°è´´å£«ï¼šå»ºè®®ç»“åˆå®é™…æƒ…å†µçµæ´»è¿ç”¨ä»¥ä¸Šå†…å®¹ã€‚"


# APIç«¯ç‚¹
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "ai-service",
        "fallback_mode": FALLBACK_MODE,
        "timestamp": datetime.now().isoformat()
    }


@app.post("/generate/xiaohongshu", response_model=GenerateResponse)
async def generate_xiaohongshu(request: XiaohongshuGenerateRequest):
    """ç”Ÿæˆå°çº¢ä¹¦å†…å®¹"""
    try:
        if not FALLBACK_MODE:
            # ä½¿ç”¨OpenAIç”Ÿæˆ
            prompt = XIAOHONGSHU_PROMPT.format(
                topic=request.topic,
                style=request.style,
                tone=request.tone,
                length=get_length_instruction(request.length),
                keywords=", ".join(request.keywords) if request.keywords else "æ— "
            )
            
            result_text = await call_openai(prompt)
            result = parse_xiaohongshu_content(result_text)
        else:
            # ä½¿ç”¨Fallbackç”Ÿæˆ
            result = FallbackGenerator.generate_xiaohongshu(
                request.topic,
                request.style,
                request.keywords
            )
        
        return GenerateResponse(
            success=True,
            data={
                "title": result["title"],
                "content": result["content"],
                "tags": result["tags"],
                "generated_at": datetime.now().isoformat(),
                "model": "fallback" if FALLBACK_MODE else DEFAULT_MODEL,
                "fallback_mode": FALLBACK_MODE
            }
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/optimize/title", response_model=GenerateResponse)
async def optimize_title(request: TitleOptimizeRequest):
    """ä¼˜åŒ–æ ‡é¢˜"""
    try:
        if not FALLBACK_MODE:
            prompt = TITLE_OPTIMIZE_PROMPT.format(
                title=request.title,
                platform=request.platform,
                count=request.count
            )
            
            result_text = await call_openai(prompt)
            titles = [line.strip() for line in result_text.split('\n') if line.strip()]
        else:
            titles = FallbackGenerator.optimize_title(request.title, request.count)
        
        return GenerateResponse(
            success=True,
            data={
                "original_title": request.title,
                "optimized_titles": titles[:request.count],
                "generated_at": datetime.now().isoformat()
            }
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/improve/content", response_model=GenerateResponse)
async def improve_content(request: ContentImproveRequest):
    """æ”¹è¿›å†…å®¹"""
    try:
        if not FALLBACK_MODE:
            prompt = CONTENT_IMPROVE_PROMPT.format(
                content=request.content,
                improvement_type=request.improvement_type
            )
            
            improved_content = await call_openai(prompt)
        else:
            improved_content = FallbackGenerator.improve_content(request.content)
        
        return GenerateResponse(
            success=True,
            data={
                "original_content": request.content,
                "improved_content": improved_content,
                "improvement_type": request.improvement_type,
                "generated_at": datetime.now().isoformat()
            }
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/analyze/sentiment", response_model=GenerateResponse)
async def analyze_sentiment(request: AnalysisRequest):
    """æƒ…æ„Ÿåˆ†æ"""
    # ç®€å•çš„æƒ…æ„Ÿåˆ†æå®ç°
    positive_words = ['å¥½', 'æ£’', 'ä¼˜ç§€', 'å–œæ¬¢', 'æ¨è', 'èµ', 'å®Œç¾', 'æ»¡æ„']
    negative_words = ['å·®', 'å', 'ç³Ÿç³•', 'å¤±æœ›', 'è®¨åŒ', 'çƒ‚', 'åƒåœ¾', 'åæ‚”']
    
    content = request.content
    positive_count = sum(1 for word in positive_words if word in content)
    negative_count = sum(1 for word in negative_words if word in content)
    
    total = positive_count + negative_count
    if total == 0:
        sentiment = "neutral"
        score = 0.5
    else:
        score = positive_count / total
        if score > 0.6:
            sentiment = "positive"
        elif score < 0.4:
            sentiment = "negative"
        else:
            sentiment = "neutral"
    
    return GenerateResponse(
        success=True,
        data={
            "sentiment": sentiment,
            "score": round(score, 2),
            "positive_count": positive_count,
            "negative_count": negative_count,
            "analyzed_at": datetime.now().isoformat()
        }
    )


@app.post("/analyze/keywords", response_model=GenerateResponse)
async def extract_keywords(request: AnalysisRequest):
    """å…³é”®è¯æå–"""
    # ç®€å•çš„å…³é”®è¯æå–å®ç°
    import jieba
    
    words = jieba.lcut(request.content)
    # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
    keywords = [w for w in words if len(w) >= 2 and w not in ['æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬', 'è¿™ä¸ª', 'é‚£ä¸ª']]
    # ç»Ÿè®¡è¯é¢‘
    from collections import Counter
    keyword_counts = Counter(keywords)
    top_keywords = keyword_counts.most_common(10)
    
    return GenerateResponse(
        success=True,
        data={
            "keywords": [{"word": word, "count": count} for word, count in top_keywords],
            "total_words": len(words),
            "analyzed_at": datetime.now().isoformat()
        }
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
